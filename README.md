# ðŸ“Š E-Commerce Data Pipeline & Analysis

A professional data workflow built with **Python**, **Pandas**, and **Plotly**. This project implements a robust ETL pipeline to clean raw transaction data and performs exploratory analysis to uncover revenue trends.

![Revenue by Country](reports/figures/revenue_by_country.png)

## Quick Start

### 1. Setup Environment
```bash
python -m venv .venv
source .\.venv\Scripts\activate
pip install -r requirements.txt
pip install -e .
```

### 2. Run the Pipeline
Process raw data into clean analytics tables:
```bash
python scripts/run_etl.py
```

### 3. Explore Results
- **Interactive Analysis**: Open `notebooks/eda.ipynb` to see dynamic **Plotly** charts.
- **Key Findings**: Read the [Summary Report](reports/summary.md).
- **Processed Data**: Found in `data/processed/` (Parquet format).

---

## ðŸ“‚ Project Flow

The data flows through the project files as follows:

```text
data/raw/                     # 1. Inputs (CSV)
â”œâ”€â”€ orders.csv
â””â”€â”€ users.csv
scripts/run_etl.py            # 2. Pipeline Execution
data/processed/               # 3. Outputs (Parquet)
â”œâ”€â”€ analytics_table.parquet   <-- Main analysis table
â”œâ”€â”€ orders_clean.parquet
â””â”€â”€ _run_meta.json
notebooks/eda.ipynb           # 4. Analysis & Viz (Plotly)
reports/                      # 5. Deliverables
â”œâ”€â”€ figures/*.png             <-- Exported Charts
â””â”€â”€ summary.md                <-- Executive Report

.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                      # Input
â”‚   â”‚   â”œâ”€â”€ orders.csv
â”‚   â”‚   â””â”€â”€ users.csv
â”‚   â””â”€â”€ processed/                # Output
â”‚       â”œâ”€â”€ analytics_table.parquet   <-- FINAL CLEAN TABLE
â”‚       â”œâ”€â”€ orders_clean.parquet
â”‚       â””â”€â”€ _run_meta.json            <-- Run metadata (row counts, timestamps)
â”‚
â”œâ”€â”€ src/bootcamp_data/            # Core Logic
â”‚   â”œâ”€â”€ etl.py                        <-- Main Pipeline Logic
â”‚   â”œâ”€â”€ transforms.py
â”‚   â””â”€â”€ joins.py
â”‚
â”œâ”€â”€ scripts/                      # Execution
â”‚   â””â”€â”€ run_etl.py                    <-- Entry point: `python scripts/run_etl.py`
â”‚
â”œâ”€â”€ notebooks/                    # Laboratory
â”‚   â””â”€â”€ eda.ipynb                     <-- Exploratory Analysis & Charts
â”‚
â””â”€â”€ reports/                      # Deliverables
    â”œâ”€â”€ figures/                      <-- Exported PNG Charts
    â””â”€â”€ summary.md                    <-- Executive Summary
```

---

## Tech Stack
- **ETL**: Custom Python pipeline with strictly typed configs.
- **Data**: Pandas for transformation, Parquet for efficient storage.
- **Viz**: **Plotly Express** for interactive visualizations.
